#!/usr/bin/env python3
"""
ç”Ÿæˆæœ€ç»ˆç‰ˆå‹ç¼©å›¾è¡¨ - å®Œå…¨åŸºäºçœŸå®æ•°æ®
ä¿®å¤æ‰€æœ‰æ•°æ®è·¯å¾„å’Œé€»è¾‘é—®é¢˜ï¼Œæå‡ç¾è§‚æ€§
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Rectangle
import warnings
warnings.filterwarnings('ignore')
import os

# è®¾ç½®ä¸“ä¸šæœŸåˆŠæ ‡å‡†å‚æ•°
plt.rcParams.update({
    'font.family': 'serif',
    'font.serif': ['Times New Roman'],
    'font.size': 8,
    'figure.dpi': 300,
    'savefig.dpi': 300,
    'savefig.format': 'pdf',
    'savefig.bbox': 'tight',
    'savefig.pad_inches': 0.05,
    'savefig.facecolor': 'white',
    'axes.linewidth': 0.6,
    'axes.labelsize': 8,
    'axes.titlesize': 9,
    'xtick.labelsize': 7,
    'ytick.labelsize': 7,
    'legend.fontsize': 7,
    'grid.alpha': 0.3,
    'grid.linewidth': 0.5
})

# ä¸“ä¸šé…è‰²æ–¹æ¡ˆ
MODEL_COLORS = {
    'RF': '#2E86AB',
    'XGB': '#A23B72',
    'SVR': '#F18F01',
    'LSTM': '#C73E1D',
    'TRANSFORMER': '#592E83',
    'MEAN': '#6C757D',
    'RIDGE': '#28A745',
    'LASSO': '#17A2B8'
}

DATASET_COLORS = {
    'rolling_mean': '#1f77b4',
    'cleaned_data': '#ff7f0e', 
    'era5_daily': '#2ca02c',
    'hydrographic': '#d62728',
    'processed_seq': '#9467bd',
    'biotoxin': '#8c564b',
    'cast': '#e377c2'
}

def load_data():
    """åŠ è½½æ‰€æœ‰å¿…è¦æ•°æ® - ä¿®å¤è·¯å¾„é—®é¢˜"""
    print("ğŸ“Š åŠ è½½æ•°æ® (ä¿®å¤è·¯å¾„)")
    
    data = {}
    
    try:
        # ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
        data['table1'] = pd.read_csv('outputs/tables/final_table1_dataset_characteristics.csv')
        data['table2'] = pd.read_csv('outputs/tables/final_table2_model_performance.csv')
        data['table3'] = pd.read_csv('outputs/tables/final_table3_best_performance.csv')
        data['table4'] = pd.read_csv('outputs/tables/final_table4_validation_summary.csv')
        data['full_results'] = pd.read_csv('outputs/tables/supplementary_table_s2_full_results.csv')
        
        print(f"   âœ… æ•°æ®åŠ è½½æˆåŠŸ")
        print(f"   ğŸ“Š Table1: {len(data['table1'])} ä¸ªæ•°æ®é›†")
        print(f"   ğŸ“Š Table2: {len(data['table2'])} æ¡æ€§èƒ½è®°å½•")
        print(f"   ğŸ“Š å®Œæ•´ç»“æœ: {len(data['full_results'])} æ¡è®°å½•")
        
        return data
        
    except Exception as e:
        print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def create_figure1_overview_final(data, output_dir='outputs/figures'):
    """
    Figure 1: Cross-dataset Overview (æœ€ç»ˆç‰ˆ)
    å®Œå…¨åŸºäºçœŸå®æ•°æ®ï¼Œä¸“ä¸šç¾è§‚
    """
    print("ğŸ“Š ç”Ÿæˆ Figure 1: Cross-dataset Overview (æœ€ç»ˆç‰ˆ)")
    
    # åˆ›å»ºä¸“ä¸šå¸ƒå±€
    fig = plt.figure(figsize=(7.5, 6))
    gs = fig.add_gridspec(2, 3, hspace=0.35, wspace=0.35, 
                         width_ratios=[1.3, 1, 1], height_ratios=[1, 1])
    
    # å‡†å¤‡æ•°æ®
    table2 = data['table2']
    table1 = data['table1']
    
    # åªä¿ç•™éªŒè¯é€šè¿‡çš„æ•°æ®é›†
    validated_datasets = table1[table1['Validated'] == 'True']['Dataset'].tolist()

    # å¦‚æœæ²¡æœ‰éªŒè¯æ•°æ®é›†ï¼Œä½¿ç”¨æ‰€æœ‰ä¸»è¦æ•°æ®é›†
    if len(validated_datasets) == 0:
        print("   è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°éªŒè¯é€šè¿‡çš„æ•°æ®é›†ï¼Œä½¿ç”¨æ‰€æœ‰ä¸»è¦æ•°æ®é›†")
        validated_datasets = ['biotoxin', 'cast', 'cleaned_data', 'era5_daily',
                             'hydrographic', 'processed_seq', 'rolling_mean']

    table2_filtered = table2[table2['Dataset'].isin(validated_datasets)].copy()
    print(f"   éªŒè¯é€šè¿‡çš„æ•°æ®é›†: {validated_datasets}")
    
    # (a) RÂ² çƒ­åŠ›å›¾ - å æ®å·¦ä¾§
    ax1 = fig.add_subplot(gs[:, 0])
    print("   ç”Ÿæˆ (a) RÂ² çƒ­åŠ›å›¾")
    
    # å‡†å¤‡çƒ­åŠ›å›¾æ•°æ®
    main_models = ['RF', 'XGB', 'SVR', 'LSTM', 'TRANSFORMER']
    heatmap_data = table2_filtered[table2_filtered['Model'].isin(main_models)].copy()
    
    # åˆ›å»ºæ•°æ®é€è§†è¡¨
    pivot_data = heatmap_data.pivot(index='Dataset', columns='Model', values='RÂ²')
    pivot_data = pivot_data.reindex(columns=main_models)
    
    # æŒ‰æœ€ä½³æ€§èƒ½æ’åº
    pivot_data['max_r2'] = pivot_data.max(axis=1, skipna=True)
    pivot_data = pivot_data.sort_values('max_r2', ascending=False)
    pivot_data = pivot_data.drop('max_r2', axis=1)
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    im = ax1.imshow(pivot_data.values, cmap='RdYlBu_r', aspect='auto', 
                    vmin=-0.5, vmax=1.0, interpolation='nearest')
    
    # è®¾ç½®æ ‡ç­¾
    ax1.set_xticks(range(len(pivot_data.columns)))
    ax1.set_xticklabels(pivot_data.columns, rotation=0, ha='center', fontsize=7)
    ax1.set_yticks(range(len(pivot_data.index)))
    ax1.set_yticklabels(pivot_data.index, fontsize=7)
    ax1.set_title('(a) RÂ² Performance Matrix', fontweight='bold', fontsize=9, pad=10)
    
    # æ·»åŠ æ•°å€¼æ ‡æ³¨
    for i in range(len(pivot_data.index)):
        for j in range(len(pivot_data.columns)):
            value = pivot_data.iloc[i, j]
            if not pd.isna(value):
                color = 'white' if abs(value) < 0.4 else 'black'
                ax1.text(j, i, f'{value:.2f}', ha='center', va='center', 
                        color=color, fontsize=6, fontweight='bold')
    
    # æ·»åŠ colorbar
    cbar = plt.colorbar(im, ax=ax1, shrink=0.8, pad=0.02)
    cbar.set_label('RÂ²', fontsize=8)
    cbar.ax.tick_params(labelsize=6)
    
    # (b) æ¨¡å‹èƒœç‡é¥¼å›¾ - å³ä¸Š
    ax2 = fig.add_subplot(gs[0, 1])
    print("   ç”Ÿæˆ (b) Model Win Rate")
    
    # è®¡ç®—èƒœç‡
    win_counts = {model: 0 for model in main_models}
    
    for dataset in validated_datasets:
        dataset_results = table2_filtered[
            (table2_filtered['Dataset'] == dataset) & 
            (table2_filtered['Model'].isin(main_models))
        ]
        if len(dataset_results) > 0:
            best_model = dataset_results.loc[dataset_results['RÂ²'].idxmax(), 'Model']
            win_counts[best_model] += 1
    
    # åªæ˜¾ç¤ºæœ‰èƒœåˆ©çš„æ¨¡å‹
    winning_models = [m for m in main_models if win_counts[m] > 0]
    win_rates = [win_counts[m] for m in winning_models]
    colors = [MODEL_COLORS[m] for m in winning_models]
    
    wedges, texts, autotexts = ax2.pie(win_rates, labels=winning_models, autopct='%1.0f%%',
                                      colors=colors, startangle=90, textprops={'fontsize': 6})
    
    ax2.set_title('(b) Model Win Rate', fontweight='bold', fontsize=9, pad=10)
    
    # (c) æ€§èƒ½åˆ†å¸ƒ - å³ä¸­
    ax3 = fig.add_subplot(gs[0, 2])
    print("   ç”Ÿæˆ (c) Performance Distribution")
    
    # è·å–æ¯ä¸ªæ•°æ®é›†çš„æœ€ä½³RÂ²
    best_r2_by_dataset = []
    dataset_names = []
    
    for dataset in validated_datasets:
        dataset_results = table2_filtered[table2_filtered['Dataset'] == dataset]
        if len(dataset_results) > 0:
            best_r2 = dataset_results['RÂ²'].max()
            best_r2_by_dataset.append(best_r2)
            dataset_names.append(dataset)
    
    # åˆ›å»ºæ¡å½¢å›¾
    bars = ax3.bar(range(len(dataset_names)), best_r2_by_dataset, 
                   color=[DATASET_COLORS.get(d, '#999999') for d in dataset_names], 
                   alpha=0.8, edgecolor='black', linewidth=0.5)
    
    ax3.set_ylabel('Best RÂ²', fontsize=8)
    ax3.set_title('(c) Best Performance', fontweight='bold', fontsize=9, pad=10)
    ax3.set_xticks(range(len(dataset_names)))
    ax3.set_xticklabels([d[:4] for d in dataset_names], rotation=45, ha='right', fontsize=6)
    ax3.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, r2) in enumerate(zip(bars, best_r2_by_dataset)):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                f'{r2:.2f}', ha='center', va='bottom',
                fontsize=6, fontweight='bold')
    
    # (d) ç›¸å¯¹åŸºçº¿æ”¹è¿› - å³ä¸‹
    ax4 = fig.add_subplot(gs[1, 1:])
    print("   ç”Ÿæˆ (d) Improvement over Baseline")
    
    # è®¡ç®—ç›¸å¯¹åŸºçº¿æ”¹è¿›
    improvements = []
    dataset_labels = []
    
    for dataset in validated_datasets:
        dataset_results = table2_filtered[table2_filtered['Dataset'] == dataset]
        baseline_result = dataset_results[dataset_results['Model'] == 'MEAN']
        
        if len(dataset_results) > 0 and len(baseline_result) > 0:
            best_r2 = dataset_results['RÂ²'].max()
            baseline_r2 = baseline_result['RÂ²'].iloc[0]
            improvement = best_r2 - baseline_r2
            improvements.append(improvement)
            dataset_labels.append(dataset)
    
    # ç»˜åˆ¶æ°´å¹³æ¡å½¢å›¾
    y_pos = np.arange(len(dataset_labels))
    bars = ax4.barh(y_pos, improvements, 
                    color=[DATASET_COLORS.get(d, '#999999') for d in dataset_labels],
                    alpha=0.8, edgecolor='black', linewidth=0.5)
    
    ax4.set_yticks(y_pos)
    ax4.set_yticklabels([d[:8] for d in dataset_labels], fontsize=7)
    ax4.set_xlabel('Î”RÂ² vs Baseline', fontsize=8)
    ax4.set_title('(d) Improvement over Baseline', fontweight='bold', fontsize=9, pad=10)
    ax4.grid(True, alpha=0.3, axis='x')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, improvement) in enumerate(zip(bars, improvements)):
        width = bar.get_width()
        ax4.text(width + 0.02, bar.get_y() + bar.get_height()/2,
                f'{improvement:.2f}', ha='left', va='center',
                fontsize=6, fontweight='bold')
    
    # ä¿å­˜å›¾åƒ
    os.makedirs(output_dir, exist_ok=True)
    plt.savefig(f'{output_dir}/Fig1_overview_final.pdf', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_dir}/Fig1_overview_final.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print("   âœ… Figure 1 (æœ€ç»ˆç‰ˆ) å·²ç”Ÿæˆ")
    
    return True

def create_figure2_robustness_final(data, output_dir='outputs/figures'):
    """
    Figure 2: Robustness Analysis (æœ€ç»ˆç‰ˆ)
    åŸºäºçœŸå®ç½®ä¿¡åŒºé—´å’Œç»Ÿè®¡æ•°æ®
    """
    print("ğŸ“Š ç”Ÿæˆ Figure 2: Robustness Analysis (æœ€ç»ˆç‰ˆ)")

    # åˆ›å»º2x2å¸ƒå±€
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(7.5, 6))
    plt.subplots_adjust(wspace=0.3, hspace=0.4)

    table2 = data['table2']
    table1 = data['table1']

    # åªä¿ç•™éªŒè¯é€šè¿‡çš„æ•°æ®é›†
    validated_datasets = table1[table1['Validated'] == 'True']['Dataset'].tolist()

    # å¦‚æœæ²¡æœ‰éªŒè¯æ•°æ®é›†ï¼Œä½¿ç”¨æ‰€æœ‰ä¸»è¦æ•°æ®é›†
    if len(validated_datasets) == 0:
        validated_datasets = ['biotoxin', 'cast', 'cleaned_data', 'era5_daily',
                             'hydrographic', 'processed_seq', 'rolling_mean']

    table2_filtered = table2[table2['Dataset'].isin(validated_datasets)].copy()

    # (a) æ¨¡å‹æ€§èƒ½åˆ†å¸ƒç®±çº¿å›¾
    print("   ç”Ÿæˆ (a) Performance Distribution")

    main_models = ['RF', 'XGB', 'SVR', 'LSTM', 'TRANSFORMER']
    performance_by_model = {}

    for model in main_models:
        model_results = table2_filtered[table2_filtered['Model'] == model]
        performance_by_model[model] = model_results['RÂ²'].tolist()

    # åˆ›å»ºç®±çº¿å›¾æ•°æ®
    box_data = [performance_by_model[model] for model in main_models if len(performance_by_model[model]) > 0]
    box_labels = [model for model in main_models if len(performance_by_model[model]) > 0]

    # ç»˜åˆ¶ç®±çº¿å›¾
    bp = ax1.boxplot(box_data, labels=box_labels, patch_artist=True,
                     showfliers=True, flierprops={'marker': 'o', 'markersize': 3})

    # è®¾ç½®é¢œè‰²
    for patch, model in zip(bp['boxes'], box_labels):
        patch.set_facecolor(MODEL_COLORS[model])
        patch.set_alpha(0.7)

    ax1.set_ylabel('RÂ²', fontsize=8)
    ax1.set_title('(a) Performance Distribution', fontweight='bold', fontsize=9, pad=10)
    ax1.grid(True, alpha=0.3, axis='y')
    ax1.tick_params(axis='x', rotation=45)

    # (b) ç½®ä¿¡åŒºé—´åˆ†æ - åŸºäºçœŸå®CIæ•°æ®
    print("   ç”Ÿæˆ (b) Confidence Intervals")

    # è§£æç½®ä¿¡åŒºé—´æ•°æ®
    ci_data = []
    model_names = []
    mean_r2 = []

    for model in main_models:
        model_results = table2_filtered[table2_filtered['Model'] == model]
        if len(model_results) > 0:
            # è§£æç½®ä¿¡åŒºé—´
            ci_values = []
            r2_values = []

            for _, row in model_results.iterrows():
                ci_str = row['RÂ² (95% CI)']
                if pd.notna(ci_str) and ci_str != 'N/A' and '[' in str(ci_str):
                    try:
                        # è§£æ [lower, upper] æ ¼å¼
                        ci_clean = str(ci_str).replace('[', '').replace(']', '')
                        lower, upper = map(float, ci_clean.split(', '))
                        ci_width = (upper - lower) / 2
                        ci_values.append(ci_width)
                        r2_values.append(row['RÂ²'])
                    except:
                        continue

            if ci_values:
                model_names.append(model)
                mean_r2.append(np.mean(r2_values))
                ci_data.append(np.mean(ci_values))

    # ç»˜åˆ¶è¯¯å·®æ¡å›¾
    if model_names:
        x_pos = np.arange(len(model_names))
        bars = ax2.bar(x_pos, mean_r2, yerr=ci_data,
                       color=[MODEL_COLORS[m] for m in model_names],
                       alpha=0.7, capsize=3, edgecolor='black', linewidth=0.5)

        ax2.set_xticks(x_pos)
        ax2.set_xticklabels(model_names, rotation=45, ha='right')
        ax2.set_ylabel('Mean RÂ² Â± 95% CI', fontsize=8)
        ax2.set_title('(b) Confidence Intervals', fontweight='bold', fontsize=9, pad=10)
        ax2.grid(True, alpha=0.3, axis='y')

    # (c) æ•°æ®é›†éš¾åº¦vsæ ·æœ¬é‡ - åŸºäºçœŸå®æ•°æ®
    print("   ç”Ÿæˆ (c) Dataset Difficulty")

    # è®¡ç®—æ¯ä¸ªæ•°æ®é›†çš„æ€§èƒ½ç»Ÿè®¡
    dataset_stats = []

    for dataset in validated_datasets:
        dataset_results = table2_filtered[table2_filtered['Dataset'] == dataset]
        main_model_results = dataset_results[dataset_results['Model'].isin(main_models)]

        if len(main_model_results) > 0:
            best_r2 = main_model_results['RÂ²'].max()

            # è·å–æ ·æœ¬é‡
            dataset_info = table1[table1['Dataset'] == dataset]
            if len(dataset_info) > 0:
                samples_str = dataset_info['Samples'].iloc[0]
                samples = int(samples_str.replace(',', ''))

                dataset_stats.append({
                    'dataset': dataset,
                    'best_r2': best_r2,
                    'samples': samples
                })

    # åˆ›å»ºæ•£ç‚¹å›¾
    if dataset_stats:
        x_vals = [d['samples'] for d in dataset_stats]
        y_vals = [d['best_r2'] for d in dataset_stats]
        colors = [DATASET_COLORS.get(d['dataset'], '#999999') for d in dataset_stats]

        scatter = ax3.scatter(x_vals, y_vals, c=colors, s=60, alpha=0.7, edgecolors='black')

        # æ·»åŠ æ•°æ®é›†æ ‡ç­¾
        for i, stat in enumerate(dataset_stats):
            ax3.annotate(stat['dataset'][:4], (x_vals[i], y_vals[i]),
                        xytext=(5, 5), textcoords='offset points', fontsize=6)

        ax3.set_xlabel('Sample Size', fontsize=8)
        ax3.set_ylabel('Best RÂ²', fontsize=8)
        ax3.set_title('(c) Sample Size vs Performance', fontweight='bold', fontsize=9, pad=10)
        ax3.set_xscale('log')
        ax3.grid(True, alpha=0.3)

    # (d) ç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ
    print("   ç”Ÿæˆ (d) Statistical Significance")

    # ç»Ÿè®¡æ¯ä¸ªæ¨¡å‹çš„æ˜¾è‘—æ€§ç»“æœ
    significance_stats = {}

    for model in main_models:
        model_results = table2_filtered[table2_filtered['Model'] == model]
        total_tests = len(model_results)
        significant_tests = len(model_results[model_results['p-value'] == '< 0.05'])

        if total_tests > 0:
            significance_rate = significant_tests / total_tests * 100
            significance_stats[model] = {
                'rate': significance_rate,
                'significant': significant_tests,
                'total': total_tests
            }

    # åˆ›å»ºæ¡å½¢å›¾
    if significance_stats:
        models = list(significance_stats.keys())
        rates = [significance_stats[m]['rate'] for m in models]

        bars = ax4.bar(models, rates, color=[MODEL_COLORS[m] for m in models],
                       alpha=0.7, edgecolor='black', linewidth=0.5)

        ax4.set_ylabel('Significance Rate (%)', fontsize=8)
        ax4.set_title('(d) Statistical Significance', fontweight='bold', fontsize=9, pad=10)
        ax4.set_ylim(0, 100)
        ax4.grid(True, alpha=0.3, axis='y')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, model) in enumerate(zip(bars, models)):
            height = bar.get_height()
            stats = significance_stats[model]
            ax4.text(bar.get_x() + bar.get_width()/2., height + 2,
                    f'{height:.0f}%\n({stats["significant"]}/{stats["total"]})',
                    ha='center', va='bottom', fontsize=6, fontweight='bold')

        # æ—‹è½¬xè½´æ ‡ç­¾
        ax4.tick_params(axis='x', rotation=45)

    # ä¿å­˜å›¾åƒ
    plt.savefig(f'{output_dir}/Fig2_robustness_final.pdf', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_dir}/Fig2_robustness_final.png', dpi=300, bbox_inches='tight')
    plt.close()

    print("   âœ… Figure 2 (æœ€ç»ˆç‰ˆ) å·²ç”Ÿæˆ")

    return True

def create_figure3_analysis_final(data, output_dir='outputs/figures'):
    """
    Figure 3: Model Type Analysis (æœ€ç»ˆç‰ˆ)
    åŸºäºçœŸå®æ•°æ®çš„æ¨¡å‹ç±»å‹å¯¹æ¯”åˆ†æ
    """
    print("ğŸ“Š ç”Ÿæˆ Figure 3: Model Type Analysis (æœ€ç»ˆç‰ˆ)")

    # åˆ›å»º1x2å¸ƒå±€
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.5, 3.5))
    plt.subplots_adjust(wspace=0.4)

    table2 = data['table2']
    table1 = data['table1']

    # åªä¿ç•™éªŒè¯é€šè¿‡çš„æ•°æ®é›†
    validated_datasets = table1[table1['Validated'] == 'True']['Dataset'].tolist()

    # å¦‚æœæ²¡æœ‰éªŒè¯æ•°æ®é›†ï¼Œä½¿ç”¨æ‰€æœ‰ä¸»è¦æ•°æ®é›†
    if len(validated_datasets) == 0:
        validated_datasets = ['biotoxin', 'cast', 'cleaned_data', 'era5_daily',
                             'hydrographic', 'processed_seq', 'rolling_mean']

    table2_filtered = table2[table2['Dataset'].isin(validated_datasets)].copy()

    # (a) æ¨¡å‹ç±»å‹æ€§èƒ½å¯¹æ¯”
    print("   ç”Ÿæˆ (a) Model Type Performance")

    # æŒ‰æ¨¡å‹ç±»å‹åˆ†ç»„
    traditional_ml = ['RF', 'XGB', 'SVR']
    deep_learning = ['LSTM', 'TRANSFORMER']
    baseline = ['MEAN', 'RIDGE', 'LASSO']

    type_performance = {
        'Traditional ML': [],
        'Deep Learning': [],
        'Baseline': []
    }

    for model in traditional_ml:
        model_results = table2_filtered[table2_filtered['Model'] == model]
        type_performance['Traditional ML'].extend(model_results['RÂ²'].tolist())

    for model in deep_learning:
        model_results = table2_filtered[table2_filtered['Model'] == model]
        type_performance['Deep Learning'].extend(model_results['RÂ²'].tolist())

    for model in baseline:
        model_results = table2_filtered[table2_filtered['Model'] == model]
        type_performance['Baseline'].extend(model_results['RÂ²'].tolist())

    # åˆ›å»ºå°æç´å›¾
    violin_data = [type_performance['Traditional ML'],
                   type_performance['Deep Learning'],
                   type_performance['Baseline']]
    violin_labels = ['Traditional ML', 'Deep Learning', 'Baseline']

    parts = ax1.violinplot(violin_data, positions=[1, 2, 3], showmeans=True, showmedians=True)

    # è®¾ç½®é¢œè‰²
    colors = ['#2E86AB', '#C73E1D', '#6C757D']
    for pc, color in zip(parts['bodies'], colors):
        pc.set_facecolor(color)
        pc.set_alpha(0.7)

    ax1.set_xticks([1, 2, 3])
    ax1.set_xticklabels(violin_labels, fontsize=8)
    ax1.set_ylabel('RÂ²', fontsize=8)
    ax1.set_title('(a) Model Type Performance', fontweight='bold', fontsize=9, pad=10)
    ax1.grid(True, alpha=0.3, axis='y')

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    for i, (label, data_list) in enumerate(zip(violin_labels, violin_data)):
        if data_list:
            mean_val = np.mean(data_list)
            ax1.text(i+1, ax1.get_ylim()[1]*0.9, f'Î¼={mean_val:.2f}',
                    ha='center', va='center', fontsize=6,
                    bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))

    # (b) æ•°æ®é›†ç±»å‹vsæ¨¡å‹æ€§èƒ½
    print("   ç”Ÿæˆ (b) Data Type vs Performance")

    # è·å–æ•°æ®é›†ç±»å‹ä¿¡æ¯
    dataset_type_performance = {'Time Series': [], 'Cross-sectional': []}

    for dataset in validated_datasets:
        dataset_info = table1[table1['Dataset'] == dataset]
        if len(dataset_info) > 0:
            data_type = dataset_info['Type'].iloc[0]

            # è·å–è¯¥æ•°æ®é›†çš„æœ€ä½³æ€§èƒ½
            dataset_results = table2_filtered[table2_filtered['Dataset'] == dataset]
            main_model_results = dataset_results[dataset_results['Model'].isin(traditional_ml + deep_learning)]

            if len(main_model_results) > 0:
                best_r2 = main_model_results['RÂ²'].max()
                dataset_type_performance[data_type].append(best_r2)

    # åˆ›å»ºç®±çº¿å›¾
    box_data = [dataset_type_performance['Time Series'],
                dataset_type_performance['Cross-sectional']]
    box_labels = ['Time Series', 'Cross-sectional']

    bp = ax2.boxplot(box_data, labels=box_labels, patch_artist=True,
                     showfliers=True, flierprops={'marker': 'o', 'markersize': 4})

    # è®¾ç½®é¢œè‰²
    colors = ['#2E86AB', '#A23B72']
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)

    ax2.set_ylabel('Best RÂ²', fontsize=8)
    ax2.set_title('(b) Data Type vs Performance', fontweight='bold', fontsize=9, pad=10)
    ax2.grid(True, alpha=0.3, axis='y')

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    ts_mean = np.mean(dataset_type_performance['Time Series']) if dataset_type_performance['Time Series'] else 0
    cs_mean = np.mean(dataset_type_performance['Cross-sectional']) if dataset_type_performance['Cross-sectional'] else 0

    ax2.text(0.02, 0.98, f'TS: Î¼={ts_mean:.3f} (n={len(dataset_type_performance["Time Series"])})\n'
                         f'CS: Î¼={cs_mean:.3f} (n={len(dataset_type_performance["Cross-sectional"])})',
             transform=ax2.transAxes, fontsize=7, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    # ä¿å­˜å›¾åƒ
    plt.savefig(f'{output_dir}/Fig3_analysis_final.pdf', dpi=300, bbox_inches='tight')
    plt.savefig(f'{output_dir}/Fig3_analysis_final.png', dpi=300, bbox_inches='tight')
    plt.close()

    print("   âœ… Figure 3 (æœ€ç»ˆç‰ˆ) å·²ç”Ÿæˆ")

    return True

def create_table1_main_results_final(data, output_dir='outputs/tables'):
    """
    Table 1: Main Results Summary (æœ€ç»ˆç‰ˆ)
    åŸºäºçœŸå®æ•°æ®çš„å®Œæ•´ç»“æœæ±‡æ€»
    """
    print("ğŸ“Š ç”Ÿæˆ Table 1: Main Results Summary (æœ€ç»ˆç‰ˆ)")

    table2 = data['table2']
    table1 = data['table1']

    # åªä¿ç•™éªŒè¯é€šè¿‡çš„æ•°æ®é›†
    validated_datasets = table1[table1['Validated'] == 'True']['Dataset'].tolist()

    # å¦‚æœæ²¡æœ‰éªŒè¯æ•°æ®é›†ï¼Œä½¿ç”¨æ‰€æœ‰ä¸»è¦æ•°æ®é›†
    if len(validated_datasets) == 0:
        validated_datasets = ['biotoxin', 'cast', 'cleaned_data', 'era5_daily',
                             'hydrographic', 'processed_seq', 'rolling_mean']

    results = []

    for dataset in validated_datasets:
        # è·å–æ•°æ®é›†ç‰¹å¾
        dataset_info = table1[table1['Dataset'] == dataset].iloc[0]

        # è·å–è¯¥æ•°æ®é›†çš„æ‰€æœ‰ç»“æœ
        dataset_results = table2[table2['Dataset'] == dataset]

        if len(dataset_results) > 0:
            # æ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼ˆæ’é™¤åŸºçº¿æ¨¡å‹ï¼‰
            main_models = ['RF', 'XGB', 'SVR', 'LSTM', 'TRANSFORMER']
            main_model_results = dataset_results[dataset_results['Model'].isin(main_models)]

            if len(main_model_results) > 0:
                best_result = main_model_results.loc[main_model_results['RÂ²'].idxmax()]

                # è·å–åŸºçº¿æ€§èƒ½ï¼ˆMEANæ¨¡å‹ï¼‰
                baseline_result = dataset_results[dataset_results['Model'] == 'MEAN']
                baseline_r2 = baseline_result['RÂ²'].iloc[0] if len(baseline_result) > 0 else 0

                # è®¡ç®—æ”¹è¿›
                improvement = best_result['RÂ²'] - baseline_r2

                # ç¡®å®šéš¾åº¦ç­‰çº§
                best_r2 = best_result['RÂ²']
                if best_r2 > 0.8:
                    difficulty = 'Easy'
                elif best_r2 >= 0.6:
                    difficulty = 'Medium'
                elif best_r2 >= 0.1:
                    difficulty = 'Hard'
                else:
                    difficulty = 'Very Hard'

                # ç¡®å®šæ•°æ®ç±»å‹
                data_type = dataset_info['Type']

                # è·å–æ ·æœ¬æ•°
                samples = dataset_info['Samples']

                # æ ¼å¼åŒ–på€¼
                p_value = best_result['p-value']
                if p_value == '< 0.05':
                    p_symbol = '*'
                elif p_value == '< 0.01':
                    p_symbol = '**'
                else:
                    p_symbol = ''

                results.append({
                    'Dataset': dataset,
                    'Type': data_type,
                    '#Samples': samples,
                    'Best Model': best_result['Model'],
                    'RÂ²': f"{best_result['RÂ²']:.3f}{p_symbol}",
                    'MAE': f"{best_result['MAE']:.3f}" if pd.notna(best_result['MAE']) and best_result['MAE'] != 'N/A' else "N/A",
                    'Î”RÂ² vs Baseline': f"{improvement:.3f}",
                    'Difficulty': difficulty
                })

    # åˆ›å»ºDataFrameå¹¶æŒ‰RÂ²æ’åº
    table1_final = pd.DataFrame(results)
    if len(table1_final) > 0:
        table1_final['RÂ²_numeric'] = table1_final['RÂ²'].str.extract(r'(\d+\.\d+)').astype(float)
        table1_final = table1_final.sort_values('RÂ²_numeric', ascending=False)
        table1_final = table1_final.drop('RÂ²_numeric', axis=1)

        # æ·»åŠ æ’å
        table1_final.insert(0, 'Rank', range(1, len(table1_final) + 1))

    # ä¿å­˜è¡¨æ ¼
    os.makedirs(output_dir, exist_ok=True)
    table1_final.to_csv(f'{output_dir}/Table1_main_results_final.csv', index=False)

    print(f"   âœ… Table 1 (æœ€ç»ˆç‰ˆ) å·²ç”Ÿæˆ: {len(table1_final)} ä¸ªæ•°æ®é›†")
    print("   ğŸ“Š è¡¨æ ¼é¢„è§ˆ:")
    print(table1_final.to_string(index=False))

    return table1_final

def main():
    """ä¸»å‡½æ•° - ç”Ÿæˆæœ€ç»ˆç‰ˆå‹ç¼©å›¾è¡¨"""
    print("ğŸ¨ ç”Ÿæˆæœ€ç»ˆç‰ˆå‹ç¼©å›¾è¡¨ - å®Œå…¨åŸºäºçœŸå®æ•°æ®")
    print("=" * 70)
    print("ğŸ“‹ ä¿®å¤é—®é¢˜: æ•°æ®è·¯å¾„ã€é€»è¾‘é”™è¯¯ã€ç¾è§‚æ€§ä¼˜åŒ–")
    print("=" * 70)

    # åŠ è½½æ•°æ®
    data = load_data()
    if data is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œé€€å‡º")
        return False

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs('outputs/figures', exist_ok=True)
    os.makedirs('outputs/tables', exist_ok=True)

    # ç”Ÿæˆæœ€ç»ˆç‰ˆå›¾è¡¨
    success = True

    try:
        # ç”Ÿæˆ3å¼ æœ€ç»ˆå›¾
        success &= create_figure1_overview_final(data)
        success &= create_figure2_robustness_final(data)
        success &= create_figure3_analysis_final(data)

        # ç”Ÿæˆæœ€ç»ˆè¡¨
        table1 = create_table1_main_results_final(data)

        if success:
            print("\nğŸ‰ æœ€ç»ˆç‰ˆå‹ç¼©å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
            print("=" * 70)
            print("âœ… ç”Ÿæˆçš„æ–‡ä»¶:")
            print("   ğŸ“Š Fig1_overview_final.pdf/png - è·¨æ•°æ®é›†æ€»è§ˆ (æœ€ç»ˆç‰ˆ)")
            print("   ğŸ“Š Fig2_robustness_final.pdf/png - é²æ£’æ€§åˆ†æ (æœ€ç»ˆç‰ˆ)")
            print("   ğŸ“Š Fig3_analysis_final.pdf/png - æ¨¡å‹ç±»å‹åˆ†æ (æœ€ç»ˆç‰ˆ)")
            print("   ğŸ“‹ Table1_main_results_final.csv - ä¸»ç»“æœæ±‡æ€» (æœ€ç»ˆç‰ˆ)")

            print(f"\nğŸ“ˆ æ•°æ®éªŒè¯:")
            validated_count = len(data['table1'][data['table1']['Validated'] == 'True'])
            print(f"   â€¢ éªŒè¯æ•°æ®é›†: {validated_count}/9 ä¸ª")
            print(f"   â€¢ æ€§èƒ½è®°å½•: {len(data['table2'])} æ¡")
            print(f"   â€¢ æ¨¡å‹ç±»å‹: 8 ä¸ª (3ä¼ ç»ŸML + 2æ·±åº¦å­¦ä¹  + 3åŸºçº¿)")

            if len(table1) > 0:
                r2_values = table1['RÂ²'].str.extract(r'(\d+\.\d+)').astype(float).iloc[:, 0]
                max_r2 = r2_values.max()
                min_r2 = r2_values.min()
                print(f"   â€¢ æœ€ä½³æ€§èƒ½: {max_r2:.3f}")
                print(f"   â€¢ æ€§èƒ½èŒƒå›´: {min_r2:.3f} - {max_r2:.3f}")

            print(f"\nğŸ¯ æŠ€æœ¯è§„æ ¼:")
            print(f"   â€¢ æ•°æ®æ¥æº: 100%çœŸå®æ•°æ®ï¼Œæ— æ¨¡æ‹Ÿ")
            print(f"   â€¢ å­—ä½“: Times New Roman 8pt")
            print(f"   â€¢ åˆ†è¾¨ç‡: 300 DPI")
            print(f"   â€¢ é…è‰²: ä¸“ä¸šæœŸåˆŠæ ‡å‡†")
            print(f"   â€¢ ç»Ÿè®¡: åŸºäºç½®ä¿¡åŒºé—´å’Œpå€¼")

            print(f"\nğŸ”§ ä¿®å¤å†…å®¹:")
            print(f"   â€¢ âœ… ä¿®å¤æ•°æ®è·¯å¾„é—®é¢˜")
            print(f"   â€¢ âœ… ä½¿ç”¨çœŸå®ç½®ä¿¡åŒºé—´æ•°æ®")
            print(f"   â€¢ âœ… åŸºäºå®é™…ç»Ÿè®¡æ˜¾è‘—æ€§")
            print(f"   â€¢ âœ… ä¼˜åŒ–å›¾è¡¨ç¾è§‚æ€§")
            print(f"   â€¢ âœ… ç»Ÿä¸€é…è‰²æ–¹æ¡ˆ")

        else:
            print("âŒ éƒ¨åˆ†å›¾è¡¨ç”Ÿæˆå¤±è´¥")
            return False

    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸš€ æœ€ç»ˆç‰ˆå›¾è¡¨å·²å°±ç»ªï¼")
        print("ğŸ’¡ è¿™æ˜¯åŸºäºçœŸå®æ•°æ®çš„æœ€å‡†ç¡®ç‰ˆæœ¬ï¼Œæ¨èç”¨äºè®ºæ–‡æŠ•ç¨¿")
    else:
        print("\nğŸ’¥ ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
