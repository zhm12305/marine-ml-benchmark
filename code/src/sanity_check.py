#!/usr/bin/env python3
"""
Label Permutation Test and Sanity Check Module
Integrated version of complete_sanity_check.py for src/ directory
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import warnings
from pathlib import Path
import sys
import os

warnings.filterwarnings('ignore')

# Add src directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def get_target_column(dataset_name, df):
    """è·å–ç›®æ ‡åˆ—"""
    target_mapping = {
        'biotoxin': 'VALUE',
        'cast': 'Bottom_D',
        'era5_daily': 'wind10',
        'cleaned_data': 'G2chla',
        'rolling_mean': 'G2chla', 
        'processed_seq': 'G2chla',
        'hydrographic': 'G2chla',
        'phyto_wide': 'Pseudo-nitzschia americana/brasiliana (cells l-1)',
        'phyto_long': 'GYMNODINIALES Karlodinium-like'
    }
    
    target_col = target_mapping.get(dataset_name)
    
    # å¦‚æœæ˜ å°„çš„åˆ—ä¸å­˜åœ¨ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„åˆ—
    if target_col not in df.columns:
        possible_targets = ['G2chla', 'chla', 'target', 'y', 'VALUE']
        for col in possible_targets:
            if col in df.columns:
                target_col = col
                break
        
        # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªæ•°å€¼åˆ—
        if target_col not in df.columns:
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            target_col = numeric_cols[-1] if len(numeric_cols) > 0 else None
    
    return target_col

def prepare_features(dataset_name, df, target_col):
    """å‡†å¤‡ç‰¹å¾ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´æ³„æ¼çš„åˆ—"""
    exclude_cols = ['Date', 'date', 'time', 'Time', target_col]
    
    # ç‰¹æ®Šå¤„ç†æŸäº›æ•°æ®é›†
    if dataset_name == 'cast':
        exclude_cols.extend(['Latitude', 'Longitude'])  # åœ°ç†åæ ‡å¯èƒ½æ³„æ¼ä½ç½®ä¿¡æ¯
    elif dataset_name == 'hydrographic':
        exclude_cols.extend(['LATITUDE', 'LONGITUDE'])
    
    # è·å–ç‰¹å¾åˆ—
    feature_cols = [col for col in df.columns if col not in exclude_cols]
    X = df[feature_cols].select_dtypes(include=[np.number])
    y = df[target_col]
    
    # ç§»é™¤ç¼ºå¤±å€¼
    mask = ~(X.isna().any(axis=1) | y.isna())
    X = X[mask]
    y = y[mask]
    
    return X, y

def quick_sanity_check(X, y, dataset_name, n_permutations=3):
    """å¿«é€Ÿsanity check"""
    print(f"ğŸ”¬ {dataset_name}: {X.shape[0]}æ ·æœ¬, {X.shape[1]}ç‰¹å¾")
    
    # 1. åŸå§‹æ ‡ç­¾è®­ç»ƒï¼ˆç®€åŒ–ç‰ˆï¼Œåªç”¨ä¸€æ¬¡åˆ†å‰²ï¼‰
    split_point = int(0.8 * len(X))
    X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]
    y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # è®­ç»ƒXGBoost
    model = xgb.XGBRegressor(n_estimators=50, random_state=42, verbosity=0)
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    
    original_r2 = r2_score(y_test, y_pred)
    
    # 2. ç½®æ¢æ ‡ç­¾è®­ç»ƒ
    permuted_r2_scores = []
    
    for perm in range(n_permutations):
        # éšæœºç½®æ¢ç›®æ ‡å˜é‡
        y_permuted = np.random.permutation(y.values)
        y_train_perm = y_permuted[:split_point]
        y_test_perm = y_permuted[split_point:]
        
        # è®­ç»ƒæ¨¡å‹
        model_perm = xgb.XGBRegressor(n_estimators=50, random_state=42, verbosity=0)
        model_perm.fit(X_train_scaled, y_train_perm)
        y_pred_perm = model_perm.predict(X_test_scaled)
        
        r2_perm = r2_score(y_test_perm, y_pred_perm)
        permuted_r2_scores.append(r2_perm)
    
    # 3. è®¡ç®—å¹³å‡ç½®æ¢RÂ²
    avg_permuted_r2 = np.mean(permuted_r2_scores)
    
    # 4. åˆ¤æ–­æ˜¯å¦é€šè¿‡sanity check
    pass_check = abs(avg_permuted_r2) < 0.15
    
    print(f"   åŸå§‹RÂ²: {original_r2:.4f}")
    print(f"   ç½®æ¢RÂ²: {avg_permuted_r2:.4f}")
    print(f"   é€šè¿‡æ£€éªŒ: {'âœ…' if pass_check else 'âŒ'}")
    
    return {
        'dataset': dataset_name,
        'original_r2': original_r2,
        'permuted_r2': avg_permuted_r2,
        'pass_sanity_check': pass_check,
        'n_features': X.shape[1],
        'n_samples': X.shape[0]
    }

def run_all_datasets_sanity_check():
    """è¿è¡Œæ‰€æœ‰æ•°æ®é›†çš„sanity check"""
    print("ğŸ” è¿è¡Œæ‰€æœ‰æ•°æ®é›†çš„Sanity Check")
    print("=" * 60)
    
    base_path = Path(__file__).parent.parent
    
    all_datasets = [
        'biotoxin', 'cast', 'era5_daily', 'cleaned_data',
        'rolling_mean', 'processed_seq', 'hydrographic',
        'phyto_wide', 'phyto_long'
    ]
    
    all_results = []
    
    for dataset in all_datasets:
        print(f"\nğŸ“Š æ£€æŸ¥ {dataset}")
        
        try:
            # åŠ è½½æ•°æ®
            data_path = base_path.parent / f'data/processed/{dataset}/clean.csv'
            df = pd.read_csv(data_path)
            
            # è·å–ç›®æ ‡åˆ—
            target_col = get_target_column(dataset, df)
            if target_col is None or target_col not in df.columns:
                print(f"âŒ æ— æ³•æ‰¾åˆ°ç›®æ ‡åˆ—")
                continue
            
            # å‡†å¤‡ç‰¹å¾
            X, y = prepare_features(dataset, df, target_col)
            
            if len(X) < 50:  # æ ·æœ¬å¤ªå°‘
                print(f"âŒ æ ·æœ¬æ•°é‡ä¸è¶³: {len(X)}")
                all_results.append({
                    'dataset': dataset,
                    'original_r2': np.nan,
                    'permuted_r2': np.nan,
                    'pass_sanity_check': False,
                    'n_features': X.shape[1] if len(X) > 0 else 0,
                    'n_samples': len(X),
                    'error': 'Insufficient samples'
                })
                continue
            
            # æ‰§è¡Œsanity check
            result = quick_sanity_check(X, y, dataset)
            all_results.append(result)
            
        except Exception as e:
            print(f"âŒ {dataset} å¤„ç†å¤±è´¥: {e}")
            all_results.append({
                'dataset': dataset,
                'original_r2': np.nan,
                'permuted_r2': np.nan,
                'pass_sanity_check': False,
                'n_features': 0,
                'n_samples': 0,
                'error': str(e)
            })
    
    return all_results

def generate_sanity_check_report(results):
    """ç”Ÿæˆsanity checkæŠ¥å‘Š"""
    print(f"\nğŸ“‹ Sanity Check æ€»ç»“æŠ¥å‘Š")
    print("=" * 60)
    
    results_df = pd.DataFrame(results)
    
    # ç»Ÿè®¡ç»“æœ
    total_datasets = len(results_df)
    passed_datasets = results_df['pass_sanity_check'].sum()
    failed_datasets = total_datasets - passed_datasets
    
    print(f"æ€»æ•°æ®é›†: {total_datasets}")
    print(f"é€šè¿‡æ£€éªŒ: {passed_datasets}")
    print(f"æœªé€šè¿‡æ£€éªŒ: {failed_datasets}")
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    print(f"\nè¯¦ç»†ç»“æœ:")
    for _, row in results_df.iterrows():
        status = "âœ…" if row['pass_sanity_check'] else "âŒ"
        original_r2 = row['original_r2'] if not pd.isna(row['original_r2']) else 'N/A'
        permuted_r2 = row['permuted_r2'] if not pd.isna(row['permuted_r2']) else 'N/A'
        print(f"  {status} {row['dataset']:15s}: åŸå§‹={original_r2}, ç½®æ¢={permuted_r2}")
    
    # æœªé€šè¿‡æ£€éªŒçš„æ•°æ®é›†
    failed_df = results_df[~results_df['pass_sanity_check']]
    if not failed_df.empty:
        print(f"\nâš ï¸ æœªé€šè¿‡æ£€éªŒçš„æ•°æ®é›†:")
        for _, row in failed_df.iterrows():
            reason = row.get('error', 'å¯èƒ½å­˜åœ¨æ•°æ®æ³„æ¼')
            print(f"   - {row['dataset']}: {reason}")
    
    # ä¿å­˜ç»“æœ
    base_path = Path(__file__).parent.parent.parent
    output_path = base_path / 'outputs' / 'tables' / 'complete_sanity_check_results.csv'
    results_df.to_csv(output_path, index=False)
    print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜: {output_path}")
    
    return results_df

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    
    print("ğŸš€ å¼€å§‹å®Œæ•´çš„Sanity CheckéªŒè¯")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æ•°æ®é›†æ£€æŸ¥
    all_results = run_all_datasets_sanity_check()
    
    # ç”ŸæˆæŠ¥å‘Š
    report_df = generate_sanity_check_report(all_results)
    
    # å…³é”®ç»“è®º
    print(f"\nğŸ¯ å…³é”®ç»“è®º:")
    passed_count = report_df['pass_sanity_check'].sum()
    total_count = len(report_df)
    
    if passed_count >= total_count * 0.8:  # 80%é€šè¿‡ç‡
        print(f"   âœ… {passed_count}/{total_count} æ•°æ®é›†é€šè¿‡sanity check")
        print(f"   âœ… å¤§éƒ¨åˆ†ç»“æœæ˜¯åˆç†çš„ï¼Œæ— æ˜æ˜¾æ•°æ®æ³„æ¼")
        print(f"   âœ… å¯ä»¥å®‰å…¨åœ°åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šè¿™äº›ç»“æœ")
    else:
        failed_datasets = report_df[~report_df['pass_sanity_check']]['dataset'].tolist()
        print(f"   âš ï¸ {len(failed_datasets)} ä¸ªæ•°æ®é›†æœªé€šè¿‡æ£€éªŒ: {failed_datasets}")
        print(f"   âš ï¸ éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥å’Œä¿®å¤")
    
    return report_df

if __name__ == "__main__":
    main()
